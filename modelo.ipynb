{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>length</th>\n",
       "      <th>chroma_stft_mean</th>\n",
       "      <th>chroma_stft_var</th>\n",
       "      <th>rms_mean</th>\n",
       "      <th>rms_var</th>\n",
       "      <th>spectral_centroid_mean</th>\n",
       "      <th>spectral_centroid_var</th>\n",
       "      <th>spectral_bandwidth_mean</th>\n",
       "      <th>spectral_bandwidth_var</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc16_var</th>\n",
       "      <th>mfcc17_mean</th>\n",
       "      <th>mfcc17_var</th>\n",
       "      <th>mfcc18_mean</th>\n",
       "      <th>mfcc18_var</th>\n",
       "      <th>mfcc19_mean</th>\n",
       "      <th>mfcc19_var</th>\n",
       "      <th>mfcc20_mean</th>\n",
       "      <th>mfcc20_var</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blues.00000.0.wav</td>\n",
       "      <td>66149</td>\n",
       "      <td>0.335406</td>\n",
       "      <td>0.091048</td>\n",
       "      <td>0.130405</td>\n",
       "      <td>0.003521</td>\n",
       "      <td>1773.065032</td>\n",
       "      <td>167541.630869</td>\n",
       "      <td>1972.744388</td>\n",
       "      <td>117335.771563</td>\n",
       "      <td>...</td>\n",
       "      <td>39.687145</td>\n",
       "      <td>-3.241280</td>\n",
       "      <td>36.488243</td>\n",
       "      <td>0.722209</td>\n",
       "      <td>38.099152</td>\n",
       "      <td>-5.050335</td>\n",
       "      <td>33.618073</td>\n",
       "      <td>-0.243027</td>\n",
       "      <td>43.771767</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blues.00000.1.wav</td>\n",
       "      <td>66149</td>\n",
       "      <td>0.343065</td>\n",
       "      <td>0.086147</td>\n",
       "      <td>0.112699</td>\n",
       "      <td>0.001450</td>\n",
       "      <td>1816.693777</td>\n",
       "      <td>90525.690866</td>\n",
       "      <td>2010.051501</td>\n",
       "      <td>65671.875673</td>\n",
       "      <td>...</td>\n",
       "      <td>64.748276</td>\n",
       "      <td>-6.055294</td>\n",
       "      <td>40.677654</td>\n",
       "      <td>0.159015</td>\n",
       "      <td>51.264091</td>\n",
       "      <td>-2.837699</td>\n",
       "      <td>97.030830</td>\n",
       "      <td>5.784063</td>\n",
       "      <td>59.943081</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blues.00000.2.wav</td>\n",
       "      <td>66149</td>\n",
       "      <td>0.346815</td>\n",
       "      <td>0.092243</td>\n",
       "      <td>0.132003</td>\n",
       "      <td>0.004620</td>\n",
       "      <td>1788.539719</td>\n",
       "      <td>111407.437613</td>\n",
       "      <td>2084.565132</td>\n",
       "      <td>75124.921716</td>\n",
       "      <td>...</td>\n",
       "      <td>67.336563</td>\n",
       "      <td>-1.768610</td>\n",
       "      <td>28.348579</td>\n",
       "      <td>2.378768</td>\n",
       "      <td>45.717648</td>\n",
       "      <td>-1.938424</td>\n",
       "      <td>53.050835</td>\n",
       "      <td>2.517375</td>\n",
       "      <td>33.105122</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blues.00000.3.wav</td>\n",
       "      <td>66149</td>\n",
       "      <td>0.363639</td>\n",
       "      <td>0.086856</td>\n",
       "      <td>0.132565</td>\n",
       "      <td>0.002448</td>\n",
       "      <td>1655.289045</td>\n",
       "      <td>111952.284517</td>\n",
       "      <td>1960.039988</td>\n",
       "      <td>82913.639269</td>\n",
       "      <td>...</td>\n",
       "      <td>47.739452</td>\n",
       "      <td>-3.841155</td>\n",
       "      <td>28.337118</td>\n",
       "      <td>1.218588</td>\n",
       "      <td>34.770935</td>\n",
       "      <td>-3.580352</td>\n",
       "      <td>50.836224</td>\n",
       "      <td>3.630866</td>\n",
       "      <td>32.023678</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blues.00000.4.wav</td>\n",
       "      <td>66149</td>\n",
       "      <td>0.335579</td>\n",
       "      <td>0.088129</td>\n",
       "      <td>0.143289</td>\n",
       "      <td>0.001701</td>\n",
       "      <td>1630.656199</td>\n",
       "      <td>79667.267654</td>\n",
       "      <td>1948.503884</td>\n",
       "      <td>60204.020268</td>\n",
       "      <td>...</td>\n",
       "      <td>30.336359</td>\n",
       "      <td>0.664582</td>\n",
       "      <td>45.880913</td>\n",
       "      <td>1.689446</td>\n",
       "      <td>51.363583</td>\n",
       "      <td>-3.392489</td>\n",
       "      <td>26.738789</td>\n",
       "      <td>0.536961</td>\n",
       "      <td>29.146694</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            filename  length  chroma_stft_mean  chroma_stft_var  rms_mean  \\\n",
       "0  blues.00000.0.wav   66149          0.335406         0.091048  0.130405   \n",
       "1  blues.00000.1.wav   66149          0.343065         0.086147  0.112699   \n",
       "2  blues.00000.2.wav   66149          0.346815         0.092243  0.132003   \n",
       "3  blues.00000.3.wav   66149          0.363639         0.086856  0.132565   \n",
       "4  blues.00000.4.wav   66149          0.335579         0.088129  0.143289   \n",
       "\n",
       "    rms_var  spectral_centroid_mean  spectral_centroid_var  \\\n",
       "0  0.003521             1773.065032          167541.630869   \n",
       "1  0.001450             1816.693777           90525.690866   \n",
       "2  0.004620             1788.539719          111407.437613   \n",
       "3  0.002448             1655.289045          111952.284517   \n",
       "4  0.001701             1630.656199           79667.267654   \n",
       "\n",
       "   spectral_bandwidth_mean  spectral_bandwidth_var  ...  mfcc16_var  \\\n",
       "0              1972.744388           117335.771563  ...   39.687145   \n",
       "1              2010.051501            65671.875673  ...   64.748276   \n",
       "2              2084.565132            75124.921716  ...   67.336563   \n",
       "3              1960.039988            82913.639269  ...   47.739452   \n",
       "4              1948.503884            60204.020268  ...   30.336359   \n",
       "\n",
       "   mfcc17_mean  mfcc17_var  mfcc18_mean  mfcc18_var  mfcc19_mean  mfcc19_var  \\\n",
       "0    -3.241280   36.488243     0.722209   38.099152    -5.050335   33.618073   \n",
       "1    -6.055294   40.677654     0.159015   51.264091    -2.837699   97.030830   \n",
       "2    -1.768610   28.348579     2.378768   45.717648    -1.938424   53.050835   \n",
       "3    -3.841155   28.337118     1.218588   34.770935    -3.580352   50.836224   \n",
       "4     0.664582   45.880913     1.689446   51.363583    -3.392489   26.738789   \n",
       "\n",
       "   mfcc20_mean  mfcc20_var  label  \n",
       "0    -0.243027   43.771767  blues  \n",
       "1     5.784063   59.943081  blues  \n",
       "2     2.517375   33.105122  blues  \n",
       "3     3.630866   32.023678  blues  \n",
       "4     0.536961   29.146694  blues  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('features_3_sec.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['filename', 'length', 'label'], axis=1)\n",
    "y = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dividimos entre el entrenamieto y la prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classificador(nn.Module):\n",
    "    def __init__(self,input_size,hidden,output_size):\n",
    "        '''\n",
    "        Define las caracteristicas de una red completamente conectada \n",
    "        de tres capas, recibe la cantidad de elementos de entrada, el \n",
    "        número de capas ocultas y el número de elementos de salida. \n",
    "        Entre cada capa agrega una función de activación logistica.\n",
    "        '''\n",
    "        super(Classificador,self).__init__()\n",
    "        \n",
    "        #Vamos a considerar que las capas no tiene bias\n",
    "        self.c1 = nn.Linear(in_features = input_size, out_features = hidden, bias = False)\n",
    "        self.c2 = nn.Linear(in_features = hidden, out_features = output_size, bias = False)\n",
    "\n",
    "        #funcion de error\n",
    "        self.funcion_error = nn.CrossEntropyLoss()\n",
    "\n",
    "        #error actual de la red\n",
    "        self.error = 0\n",
    "        \n",
    "    def feed_forward(self,X):\n",
    "        '''\n",
    "        Define una función que de como resultado realizar la propagación\n",
    "        hacia adelante de los elementos de X en la red definida.\n",
    "        '''\n",
    "        capa_oculta = torch.sigmoid(self.c1(X))\n",
    "        salida = torch.sigmoid(self.c2(capa_oculta))\n",
    "        # salida = self.c2(capa_oculta)\n",
    "\n",
    "        return salida\n",
    "    \n",
    "    def back_propagate(self,X,Y):\n",
    "        '''\n",
    "        Define una función que realice la propagación hacia atras usando \n",
    "        la función de error de entropia cruzada.\n",
    "        '''\n",
    "        #hacemos feed forward\n",
    "        salida = self.feed_forward(X)\n",
    "\n",
    "        #usamos la funcion de error de entropia cruzada y calculamos el error\n",
    "        self.error = self.funcion_error(salida, Y)\n",
    "\n",
    "        #hacemos backpropagation\n",
    "        self.error.backward()\n",
    "        \n",
    "    def train(self,train_X,train_Y,optimizer,ciclos=100):\n",
    "        '''\n",
    "        Define una función de entrenamiento para la red, la cual utilice\n",
    "        al conjunto de entrenamiento y el algoritmo de optimización que se \n",
    "        obtenga como parametro. Al finalizar los ciclos muestra la gráfica \n",
    "        del error.\n",
    "        '''\n",
    "        #usamos el metodo de optimizacion dado\n",
    "        self.optimizer = optimizer\n",
    "        errores_lista = []\n",
    "        epocas = [i for i in range(1, ciclos + 1)]\n",
    "\n",
    "        #entrenamos la red\n",
    "        for _ in range(ciclos):\n",
    "            #\"limipiamos los gradientes\"\n",
    "            self.optimizer.zero_grad()\n",
    "            #hacemos backpropagation y actualizamos los pesos\n",
    "            self.back_propagate(train_X, train_Y)\n",
    "            self.optimizer.step()\n",
    "\n",
    "            #calculamos el error y lo guardamos en la lista\n",
    "            errores_lista.append(self.error.item())\n",
    "\n",
    "        #graficamos el error\n",
    "        plt.plot(epocas, errores_lista, color = '#8315C2')\n",
    "        plt.grid(True)\n",
    "        plt.xlabel('Cíclos')\n",
    "        plt.ylabel('Error')\n",
    "        plt.title('Error de la Red Neuronal')\n",
    "        plt.show()        \n",
    "\n",
    "    def confusion(self,test_X,test_Y):\n",
    "        '''\n",
    "        Muestra la matriz de confusión que presenta los valores actuales de\n",
    "        la red, respecto al conjunto de datos que se decida usar.\n",
    "        '''\n",
    "        with torch.no_grad():\n",
    "            #obtenemos las predicciones y redondeamos \n",
    "            y_pred =self.feed_forward(test_X)\n",
    "            y_pred_class = y_pred.round()\n",
    "            \n",
    "            #Primera matriz de confusion\n",
    "            matriz_confusion = torch.zeros((2, 2))\n",
    "\n",
    "            TP = torch.sum(torch.logical_and(y_pred_class, test_Y))\n",
    "            matriz_confusion[0, 0] = TP\n",
    "\n",
    "            TN = torch.logical_and(torch.logical_not(y_pred_class), torch.logical_not(test_Y))\n",
    "            matriz_confusion[1, 1] = torch.sum(TN)\n",
    "\n",
    "            FP = torch.logical_and(y_pred_class, torch.logical_not(test_Y))\n",
    "            matriz_confusion[1, 0] = torch.sum(FP)\n",
    "\n",
    "            FN = torch.logical_and(torch.logical_not(y_pred_class), test_Y)\n",
    "            matriz_confusion[0, 1] = torch.sum(FN)\n",
    "            \n",
    "            #pasamos la matriz a un data frame\n",
    "            df = pd.DataFrame(matriz_confusion, index = ['Positivo', 'Negativo'], columns = ['Positivo', 'Negativo'])\n",
    "\n",
    "            print(df)\n",
    "            print()\n",
    "            \n",
    "            #segunda matriz de confusion\n",
    "            pred = torch.max(self.feed_forward(test_X), 1)[1]\n",
    "            ytrue = torch.max(test_Y, 1)[1]\n",
    "            matriz_confusion = confusion_matrix(ytrue, pred)\n",
    "            print(matriz_confusion)\n",
    "\n",
    "            #calculamos el accuracy\n",
    "            accuracy = (pred == ytrue).sum().item() / len(pred)\n",
    "            print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(RedAdam.parameters(), lr = 0.01)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
